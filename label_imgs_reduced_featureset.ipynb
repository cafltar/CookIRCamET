{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3348a0c-1407-4c14-ad37-11cd69f027fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import traceback\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from utils_segmentation import *\n",
    "\n",
    "plots = True\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['y', 'r', 'g','w','b','m','c','k'])\n",
    "norm = mpl.colors.BoundaryNorm([0,1,2,3,4,5,6,7,8], cmap.N)\n",
    "\n",
    "noon_thresh = 20#degrees\n",
    "\n",
    "start_dates_cook_v1_v2 = pd.read_excel(os.path.join(p0,'StartStopDates.xlsx')).Start.str.strip(\"'\").values.tolist()\n",
    "start_dates_cook_v3 = pd.read_excel(os.path.join(p1,'StartStopDates.xlsx')).astype({'Start':'str'}).Start.values.tolist()\n",
    "stop_dates_cook_v1_v2 = pd.read_excel(os.path.join(p0,'StartStopDates.xlsx')).Stop.str.strip(\"'\").values.tolist()\n",
    "stop_dates_cook_v3 = pd.read_excel(os.path.join(p1,'StartStopDates.xlsx')).astype({'Stop':'str'}).Stop.values.tolist()\n",
    "\n",
    "start_dates_cprl_v1_v2 = pd.read_excel(os.path.join(p00,'StartStopDates.xlsx'),dtype={'Start':str,'Stop':str}).Start.str.strip(\"'\").values.tolist()\n",
    "start_dates_cprl_v3 = pd.read_excel(os.path.join(p11,'StartStopDates.xlsx'),dtype={'Start':str,'Stop':str}).Start.str.strip(\"'\").values.tolist()\n",
    "stop_dates_cprl_v1_v2 = pd.read_excel(os.path.join(p00,'StartStopDates.xlsx'),dtype={'Start':str,'Stop':str}).Stop.str.strip(\"'\").values.tolist()\n",
    "stop_dates_cprl_v3 = pd.read_excel(os.path.join(p11,'StartStopDates.xlsx'),dtype={'Start':str,'Stop':str}).Stop.str.strip(\"'\").values.tolist()\n",
    "\n",
    "start_dates_cook_v1_v2 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in start_dates_cook_v1_v2]\n",
    "stop_dates_cook_v1_v2 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in stop_dates_cook_v1_v2]\n",
    "\n",
    "start_dates_cprl_v1_v2 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in start_dates_cprl_v1_v2]\n",
    "stop_dates_cprl_v1_v2 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in stop_dates_cprl_v1_v2]\n",
    "\n",
    "start_dates_cook_v3 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in start_dates_cook_v3]\n",
    "stop_dates_cook_v3 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in stop_dates_cook_v3]\n",
    "\n",
    "start_dates_cprl_v3 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in start_dates_cprl_v3]\n",
    "stop_dates_cprl_v3 = [pytz.utc.localize(datetime.strptime(d, '%Y%m%d%H%M%S')) for d in stop_dates_cprl_v3]\n",
    "\n",
    "model_pa_v1 = pickle.load(open(os.path.join(p3,'model_pipeline_V1_pa_batch_20241124_reduced.pk.sav'), 'rb'))\n",
    "model_pa_v2 = pickle.load(open(os.path.join(p3,'model_pipeline_V2_pa_batch_20241124_reduced.pk.sav'), 'rb'))\n",
    "model_pa_v3 = pickle.load(open(os.path.join(p3,'model_pipeline_V3_pa_batch_20241124_reduced.pk.sav'), 'rb'))\n",
    "model_pa_all = pickle.load(open(os.path.join(p3,'model_pipeline_all_pa_batch_20241205_reduced.pk.sav'), 'rb'))\n",
    "\n",
    "keep_pa_v1 = pickle.load(open(os.path.join(p3,'input_vars_V1_pa_batch_20241124_reduced.pk.sav'), 'rb'))\n",
    "keep_pa_v2 = pickle.load(open(os.path.join(p3,'input_vars_V2_pa_batch_20241124_reduced.pk.sav'), 'rb'))\n",
    "keep_pa_v3 = pickle.load(open(os.path.join(p3,'input_vars_V3_pa_batch_20241124_reduced.pk.sav'), 'rb'))\n",
    "keep_pa_all = pickle.load(open(os.path.join(p3,'input_vars_all_pa_batch_20241205_reduced.pk.sav'), 'rb'))\n",
    "\n",
    "cal_nsar_v0 = pickle.load(open(os.path.join(p3,'calibration_nsar1.pk.sav'), 'rb'))#20220705\n",
    "cal_nsar_v1 = pickle.load(open(os.path.join(p3,'calibration_nsar2.pk.sav'), 'rb'))#20221122\n",
    "cal_nsar_v2 = pickle.load(open(os.path.join(p3,'calibration_nsar3.pk.sav'), 'rb'))#20230315\n",
    "[model0,model1,model2,I0,I1] = pickle.load(open(os.path.join(p3,'calibration_nsar_pwlf.pk.sav'), 'rb'))#V3\n",
    "[model0_v3,model1_v3,model2_v3,I0_v3,I1_v3] = pickle.load(open(os.path.join(p3,'calibration_nsar_pwlf_v3.pk.sav'), 'rb'))#V3\n",
    "cal_nsar_v3 = pickle.load(open(os.path.join(p3,'calibration_nsar_lf_v3.pk.sav'), 'rb'))#V3\n",
    "cal_cprl_v3 = pickle.load(open(os.path.join(p3,'calibration_cprl_lf_v3.pk.sav'), 'rb'))#V3\n",
    "[fit0,fit1,fit2,J0,J1] = pickle.load(open(os.path.join(p3,'calibration_cprl_pwlf.pk.sav'), 'rb'))#V3\n",
    "\n",
    "cal_cprl = pickle.load(open(os.path.join(p3,'calibration_cprl1.pk.sav'), 'rb'))#20230305\n",
    "\n",
    "print('%3.4fx%3.4f'%(cal_cprl_v3.coef_[0][0],cal_cprl_v3.intercept_))\n",
    "print('%3.4fx+%3.4f x<%3.4f'%(fit0.coef_[0][0],fit0.intercept_,J0))\n",
    "print('%3.5fx+%3.4f %3.5f<=x<%3.4f'%(fit1.coef_[0][0],fit1.intercept_,J0,J1))\n",
    "print('%3.4fx+%3.4f x>=%3.4f'%(fit2.coef_[0][0],fit2.intercept_,J1))\n",
    "\n",
    "print('Linear CPRL')\n",
    "print('%3.4fx%3.4f'%(cal_cprl_v3.coef_[0][0],cal_cprl_v3.intercept_))\n",
    "print('Linear NSAR')\n",
    "print('%3.4fx%3.4f'%(cal_nsar_v3.coef_[0][0],cal_nsar_v3.intercept_))\n",
    "\n",
    "print('PW Linear CPRL')\n",
    "print('%3.4fx+%3.4f x<%3.4f'%(fit0.coef_[0][0],fit0.intercept_,J0))\n",
    "print('%3.5fx+%3.4f %3.5f<=x<%3.4f'%(fit1.coef_[0][0],fit1.intercept_,J0,J1))\n",
    "print('%3.4fx+%3.4f x>=%3.4f'%(fit2.coef_[0][0],fit2.intercept_,J1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('PW Linear NSAR')\n",
    "print(model0_v3['linearregression'].coef_[0][1:])\n",
    "print(model0_v3['linearregression'].intercept_)\n",
    "print(model1_v3['linearregression'].coef_[0][1:])\n",
    "print(model1_v3['linearregression'].intercept_)\n",
    "print(model2_v3['linearregression'].coef_[0][1:])\n",
    "print(model2_v3['linearregression'].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ccdfb-b98e-45f8-ab69-7b2888eac1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for di, versions, models, keeps, start_dates, stop_dates in zip([p0,p1,p00,p11],\n",
    "#                                                          [['V1','V2'],['V3'],['V1','V2'],['V3']],\n",
    "#                                                          [[model_pa_v1,model_pa_v2],[model_pa_v3],[model_pa_v1,model_pa_v2],[model_pa_v3]],\n",
    "#                                                          [[keep_pa_v1,keep_pa_v2],[keep_pa_v3],[keep_pa_v1,keep_pa_v2],[keep_pa_v3]],\n",
    "#                                                          [start_dates_cook_v1_v2,start_dates_cook_v3,start_dates_cprl_v1_v2,start_dates_cprl_v3],\n",
    "#                                                          [stop_dates_cook_v1_v2, stop_dates_cook_v3,stop_dates_cprl_v1_v2,stop_dates_cprl_v3]):\n",
    "\n",
    "for di, versions, models, keeps, start_dates, stop_dates in zip([p11],\n",
    "                                                         [['V3']],\n",
    "                                                         [[model_pa_v3]],\n",
    "                                                         [[keep_pa_v3]],\n",
    "                                                         [start_dates_cprl_v3],\n",
    "                                                         [stop_dates_cprl_v3]):\n",
    "# for di, versions, models, keeps, start_dates, stop_dates in zip([p0,p1,p00,p11],\n",
    "#                                                          [['V1','V2'],['V3'],['V1','V2'],['V3']],\n",
    "#                                                          [[model_pa_all,model_pa_all],[model_pa_all],[model_pa_all,model_pa_all],[model_pa_all]],\n",
    "#                                                          [[keep_pa_all,keep_pa_all],[keep_pa_all],[keep_pa_all,keep_pa_all],[keep_pa_all]],\n",
    "#                                                          [start_dates_cook_v1_v2,start_dates_cook_v3,start_dates_cprl_v1_v2,start_dates_cprl_v3],\n",
    "#                                                          [stop_dates_cook_v1_v2, stop_dates_cook_v3,stop_dates_cprl_v1_v2,stop_dates_cprl_v3]):\n",
    "\n",
    "# for di, versions, models, keeps, start_dates, stop_dates in zip([p00,p11],\n",
    "#                                                          [['V1','V2'],['V3']],\n",
    "#                                                          [[model_pa_all,model_pa_all],[model_pa_all]],\n",
    "#                                                          [[keep_pa_all,keep_pa_all],[keep_pa_all]],\n",
    "#                                                          [start_dates_cprl_v1_v2,start_dates_cprl_v3],\n",
    "#                                                          [stop_dates_cprl_v1_v2,stop_dates_cprl_v3]):\n",
    "\n",
    "    pred_pa=None\n",
    "    pred_pa_noon=None\n",
    "    warp_mat = None\n",
    "    warp_mat_assigned = False\n",
    "\n",
    "    lat = np.nan\n",
    "    lon = np.nan\n",
    "    ti = 0\n",
    "    ti_change = True\n",
    "    imgs=[]\n",
    "    f_sol_sun = []\n",
    "    f_sol_shd = []\n",
    "    f_res_sun = []\n",
    "    f_res_shd = []\n",
    "    f_veg_sun = []\n",
    "    f_veg_shd = []\n",
    "    f_snw_sun = []\n",
    "    f_snw_shd = []\n",
    "\n",
    "    T_sol_sun = []\n",
    "    T_sol_shd = []\n",
    "    T_res_sun = []\n",
    "    T_res_shd = []\n",
    "    T_veg_sun = []\n",
    "    T_veg_shd = []\n",
    "    T_snw_sun = []\n",
    "    T_snw_shd = []\n",
    "\n",
    "    elevation = []\n",
    "    azimuth = []\n",
    "\n",
    "    times = []\n",
    "    \n",
    "    daylight = []\n",
    "\n",
    "    noon_delta_new = 100\n",
    "    noon_delta_old = 100\n",
    "    n_img=0\n",
    "         \n",
    "    for version, model, keep in zip(versions,models,keeps):\n",
    "\n",
    "        pred_pa=None\n",
    "        pred_pa_noon=None\n",
    "        warp_mat = None\n",
    "        warp_mat_assigned = False\n",
    "        \n",
    "        f_imgs_ir = list()\n",
    "        f_imgs_bgr = list()\n",
    "        utc_ir = list()\n",
    "        utc_bgr = list()\n",
    "        for f in os.listdir(os.path.join(di,version)):\n",
    "            if '.png' in f:\n",
    "                time_place = f.split('.png')[0].split('_')\n",
    "                if version=='V1': \n",
    "                    t_meas = pytz.utc.localize(datetime.strptime(time_place[0],'%Y%m%d%H%M%S'))\n",
    "                elif version=='V2' or version=='V3':\n",
    "                    if di==p0 or di==p1 or di==p11:\n",
    "                        t_meas = pytz.utc.localize(datetime.strptime(time_place[0]+time_place[1],'%Y%m%d%H%M%S'))\n",
    "                    elif di==p00:\n",
    "                        t_meas = pytz.utc.localize(datetime.strptime(time_place[0],'%Y%m%d%H%M%S'))\n",
    "                if '_bgr' in f:\n",
    "                    f_imgs_bgr.append(f)\n",
    "                    utc_bgr.append(t_meas)\n",
    "                if '_ir' in f:\n",
    "                    f_imgs_ir.append(f)\n",
    "                    utc_ir.append(t_meas)\n",
    "\n",
    "        ibgr = np.argsort(utc_bgr)\n",
    "        iir = np.argsort(utc_ir)\n",
    "        utc_bgr = np.array(utc_bgr)[ibgr]\n",
    "        utc_ir = np.array(utc_ir)[iir]\n",
    "        f_imgs_bgr = np.array(f_imgs_bgr)[ibgr]\n",
    "        f_imgs_ir = np.array(f_imgs_ir)[iir]\n",
    "\n",
    "        #find closest IR match to BGR\n",
    "        idx = []\n",
    "        for utc, f in zip(utc_bgr,f_imgs_bgr):\n",
    "            idx.append(np.argmin(np.abs(utc_ir-utc)))\n",
    "\n",
    "        utc_ir = np.array(utc_ir)[idx]\n",
    "        f_imgs_ir = np.array(f_imgs_ir)[idx]\n",
    "        for f_bgr, f_ir in zip(f_imgs_bgr,f_imgs_ir):\n",
    "            bgr = cv2.imread(os.path.join(di,version,f_bgr),cv2.IMREAD_UNCHANGED)\n",
    "            #filter nighttime\n",
    "            #20221017084722_-117.081903_46.781495_bgr.png\n",
    "            time_place = f_bgr.split('_bgr.')[0].split('_')\n",
    "            if version=='V1':\n",
    "                utc = pytz.utc.localize(datetime.strptime(time_place[0], '%Y%m%d%H%M%S'))\n",
    "            elif version=='V2' or version=='V3':\n",
    "                if di==p0 or di==p1 or di==p11:\n",
    "                    utc = pytz.utc.localize(datetime.strptime(time_place[0]+time_place[1],'%Y%m%d%H%M%S'))\n",
    "                elif di==p00:\n",
    "                    utc = pytz.utc.localize(datetime.strptime(time_place[0], '%Y%m%d%H%M%S'))\n",
    "            if utc>=start_dates[ti] and utc<=stop_dates[ti]: \n",
    "                theta = np.nan\n",
    "                phi = np.nan\n",
    "                if version == 'V1':\n",
    "                    if 'nofix' not in time_place:\n",
    "                        lat = np.double(time_place[2])\n",
    "                        lon = np.double(time_place[1])\n",
    "                    elif 'nofix' in time_place and di==p00:\n",
    "                        #Latitude: 35 ° 11’ 17.45”; Longitude: 102° 5’ 43.98”; elevation : 1168 m\n",
    "                        lat = 35+11/60+17.45/3600\n",
    "                        lon = -(102+5/60+43.98/3600)\n",
    "                    else:\n",
    "                        pass\n",
    "                elif version == 'V2' or version == 'V3':\n",
    "                    if di == p0 or di == p1:\n",
    "                        lat = 46.781553\n",
    "                        lon = -117.081863\n",
    "                    elif di == p00 or di==p11:\n",
    "                        lat = 35+11/60+17.45/3600\n",
    "                        lon = -(102+5/60+43.98/3600)\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "                theta = solar.get_altitude(lat,lon,utc)\n",
    "                phi = solar.get_azimuth(lat,lon,utc)\n",
    "                day = False\n",
    "                try:\n",
    "                    _,_,v = cv2.split(cv2.cvtColor(bgr,cv2.COLOR_BGR2HSV))\n",
    "                    if theta>10.0:\n",
    "                        day = True\n",
    "                        feat,_ = get_features(bgr,keep)\n",
    "    \n",
    "                        if not np.any(np.isnan(feat)):\n",
    "                            pred_pa = model.predict(feat).reshape(bgr.shape[0:2]).astype(np.float)\n",
    "                            if plots and ti_change:\n",
    "                                plt.imshow(bgr)\n",
    "                                plt.title('bgr')\n",
    "                                #plt.savefig(os.path.join(p4,di.split('/')[-1].lower()+version+'_'+datetime.strftime(utc,'%Y%m%d%H%M%S')+'_bgr.png'),dpi=300)\n",
    "                                #plt.close()\n",
    "                                plt.show()\n",
    "                                plt.imshow(pred_pa, cmap=cmap, norm=norm, interpolation='none')\n",
    "                                plt.title('labels')\n",
    "                                #plt.savefig(os.path.join(p4,di.split('/')[-1].lower()+version+'_'+datetime.strftime(utc,'%Y%m%d%H%M%S')+'_lab.png'),dpi=300)\n",
    "                                #plt.close()\n",
    "                                plt.show()\n",
    "                        \n",
    "                        ir_good = False \n",
    "                        if os.path.getsize(os.path.join(di,version,f_ir))>10000:\n",
    "                            ir_raw = cv2.imread(os.path.join(di,version,f_ir),cv2.IMREAD_UNCHANGED)\n",
    "                            \n",
    "                            if np.std(ir_raw)<1000:\n",
    "                                ir_good = True\n",
    "                            else:\n",
    "                                ir_good = False\n",
    "                        if ir_good:\n",
    "                            if (not warp_mat_assigned):\n",
    "                                print(f_bgr)\n",
    "                                if di==p0:\n",
    "                                    if utc<stop_dates[0]:\n",
    "                                        aff_df = pd.read_csv(os.path.join(p0,'AffineCoords20221028.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                    elif utc>=start_dates[1] and utc<stop_dates[1]:\n",
    "                                        aff_df = pd.read_csv(os.path.join(p0,'AffineCoords20221109.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                    elif utc>=start_dates[2] and utc<stop_dates[2]:\n",
    "                                        aff_df = pd.read_csv(os.path.join(p0,'AffineCoords20221127.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                    elif utc>=start_dates[3] and utc<stop_dates[3]:\n",
    "                                        aff_df = pd.read_csv(os.path.join(p0,'AffineCoords20221229.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                    elif utc>=start_dates[4] and utc<stop_dates[4]:\n",
    "                                        aff_df = pd.read_csv(os.path.join(p0,'AffineCoords20230320.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                    elif utc>=start_dates[5] and utc<stop_dates[5]:\n",
    "                                        aff_df = pd.read_csv(os.path.join(p0,'AffineCoords20230520.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                    elif utc>=start_dates[6]:\n",
    "                                        aff_df = pd.read_csv(os.path.join(p0,'AffineCoords20230520.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                elif di==p1:\n",
    "                                    if utc<pytz.utc.localize(datetime.strptime('20240510223000', '%Y%m%d%H%M%S')):        \n",
    "                                        aff_df = pd.read_csv(os.path.join(p1,'AffineCoords20230908_full.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                    else:        \n",
    "                                        aff_df = pd.read_csv(os.path.join(p1,'AffineCoords20240510.csv'))\n",
    "                                        dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                        srcXY=aff_df[['IRx','IRy']].values\n",
    "                                        warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                elif di==p00:\n",
    "                                    #CPRL\n",
    "                                    aff_df = pd.read_csv(os.path.join(p00,'AffineCoords20230623.csv'))\n",
    "                                    dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                    srcXY=aff_df[['IRx','IRy']].values\n",
    "                                    warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                elif di==p11:\n",
    "                                    #CPRL\n",
    "                                    aff_df = pd.read_csv(os.path.join(p11,'AffineCoords20240723.csv'))\n",
    "                                    dstXY=aff_df[['RGBx','RGBy']].values\n",
    "                                    srcXY=aff_df[['IRx','IRy']].values\n",
    "                                    warp_mat = cv2.estimateAffine2D(srcXY,dstXY)\n",
    "                                warp_mat_assigned = True\n",
    "                            \n",
    "                            if ti_change:\n",
    "                                if di==p0:\n",
    "                                    if utc<=start_dates[5]:\n",
    "                                        mask = (pred_pa==3) | (pred_pa==7)                                    \n",
    "                                # elif di==p00:\n",
    "                                #     if utc<=start_dates[3] and utc>=stop_dates[2]:\n",
    "                                #         mask = (pred_pa==3) | (pred_pa==7)\n",
    "                                    \n",
    "                            _,ir = register_ir(ir_raw,v.reshape(bgr.shape[0:2]),bgr,warp_mat=warp_mat)\n",
    "                            T_ir = ir.astype(np.float)\n",
    "                            \n",
    "                            \n",
    "                            if version=='V3':\n",
    "                                T_ir_ = T_ir.reshape(-1)\n",
    "                                if di==p0 or di==p1:\n",
    "                                    tmp = cal_nsar_v3.predict(T_ir_.reshape(-1,1))\n",
    "                                    T_ir_ = tmp.reshape(-1)\n",
    "                                    T_ir = T_ir_.reshape(T_ir.shape)\n",
    "                                    T_ir[T_ir==cal_nsar_v3.intercept_] = np.nan\n",
    "                                else:\n",
    "                                    T_ir = np.piecewise(T_ir, [T_ir < J0, (T_ir>=J0) & (T_ir<J1), T_ir>=J1], [lambda x: fit0.intercept_[0]+fit0.coef_[0][0]*x, lambda x: fit1.intercept_[0]+fit1.coef_[0][0]*x, lambda x: fit2.intercept_[0]+fit2.coef_[0][0]*x])\n",
    "                                    T_ir[T_ir==fit0.intercept_] = np.nan\n",
    "                            else:\n",
    "                                T_ir = np.piecewise(T_ir, [T_ir < I0, (T_ir>=I0) & (T_ir<I1), T_ir>=I1], [lambda x: model0.intercept_[0]+model0.coef_[0][0]*x, lambda x: model1.intercept_[0]+model1.coef_[0][0]*x, lambda x: model2.intercept_[0]+model2.coef_[0][0]*x])\n",
    "                                T_ir[T_ir==model0.intercept_] = np.nan\n",
    "                            \n",
    "                            if di==p0:\n",
    "                                if utc<start_dates[5]:\n",
    "                                    T_ir[mask] = np.nan\n",
    "                                    pred_pa[mask] = np.nan\n",
    "                            # elif di==p00:\n",
    "                            #     if utc<=start_dates[3] and utc>=stop_dates[2]:\n",
    "                            #         T_ir[mask] = np.nan\n",
    "                            #         pred_pa[mask] = np.nan      \n",
    "                                    \n",
    "                            \n",
    "                            T_ir = T_ir*(1/.98)**(1/4)\n",
    "                            if plots and ti_change:\n",
    "                                plt.imshow(T_ir)\n",
    "                                plt.colorbar()\n",
    "                                plt.savefig(os.path.join(p4,di.split('/')[-1].lower()+version+'_'+datetime.strftime(utc,'%Y%m%d%H%M%S')+'_tir.png'),dpi=300)\n",
    "                                plt.close()\n",
    "                                #plt.show()\n",
    "                        else:\n",
    "                            T_ir = np.nan*v.reshape(bgr.shape[0:2])\n",
    "    \n",
    "                        noon_delta_new = np.abs(theta-90) \n",
    "                        if noon_delta_new<noon_delta_old:#near noon\n",
    "                            pred_pa_noon=pred_pa.copy()\n",
    "                        noon_delta_old = noon_delta_new\n",
    "                        f_sol_sun.append(np.nansum(pred_pa==0)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        f_sol_shd.append(np.nansum(pred_pa==4)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        f_res_sun.append(np.nansum(pred_pa==1)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        f_res_shd.append(np.nansum(pred_pa==5)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        f_veg_sun.append(np.nansum(pred_pa==2)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        f_veg_shd.append(np.nansum(pred_pa==6)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        f_snw_sun.append(np.nansum(pred_pa==3)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        f_snw_shd.append(np.nansum(pred_pa==7)/pred_pa.shape[0]/pred_pa.shape[1])\n",
    "                        \n",
    "                        T_sol_sun.append(np.nanmean(T_ir[pred_pa==0]))\n",
    "                        T_sol_shd.append(np.nanmean(T_ir[pred_pa==4]))\n",
    "                        T_res_sun.append(np.nanmean(T_ir[pred_pa==1]))\n",
    "                        T_res_shd.append(np.nanmean(T_ir[pred_pa==5]))\n",
    "                        T_veg_sun.append(np.nanmean(T_ir[pred_pa==2]))\n",
    "                        T_veg_shd.append(np.nanmean(T_ir[pred_pa==6]))\n",
    "                        T_snw_sun.append(np.nanmean(T_ir[pred_pa==3]))\n",
    "                        T_snw_shd.append(np.nanmean(T_ir[pred_pa==7]))\n",
    "                    else:#night \n",
    "                        day = False\n",
    "                        if pred_pa_noon is not None:\n",
    "    \n",
    "                            ir_good = False\n",
    "    \n",
    "                            if os.path.getsize(os.path.join(di,version,f_ir))>10000:\n",
    "                                ir_raw = cv2.imread(os.path.join(di,version,f_ir),cv2.IMREAD_UNCHANGED)\n",
    "                                if np.std(ir_raw)<1000:\n",
    "                                    ir_good = True\n",
    "                                else:\n",
    "                                    ir_good = False\n",
    "                            if ir_good:\n",
    "                                _,ir = register_ir(ir_raw,v.reshape(bgr.shape[0:2]),bgr,warp_mat=warp_mat)\n",
    "                                T_ir = ir.astype(np.float)\n",
    "                                #\n",
    "                                if version=='V3':\n",
    "                                    T_ir_ = T_ir.reshape(-1)\n",
    "                                    if di==p0 or di==p1:\n",
    "                                        tmp = cal_nsar_v3.predict(T_ir_.reshape(-1,1))\n",
    "                                        T_ir_ = tmp.reshape(-1)\n",
    "                                        T_ir = T_ir_.reshape(T_ir.shape)\n",
    "                                        T_ir[T_ir==cal_nsar_v3.intercept_] = np.nan\n",
    "                                    else:\n",
    "                                        T_ir = np.piecewise(T_ir, [T_ir < J0, (T_ir>=J0) & (T_ir<J1), T_ir>=J1], [lambda x: fit0.intercept_[0]+fit0.coef_[0][0]*x, lambda x: fit1.intercept_[0]+fit1.coef_[0][0]*x, lambda x: fit2.intercept_[0]+fit2.coef_[0][0]*x])\n",
    "                                        T_ir[T_ir==fit0.intercept_] = np.nan\n",
    "                                else:\n",
    "                                    T_ir = np.piecewise(T_ir, [T_ir < I0, (T_ir>=I0) & (T_ir<I1), T_ir>=I1], [lambda x: model0.intercept_[0]+model0.coef_[0][0]*x, lambda x: model1.intercept_[0]+model1.coef_[0][0]*x, lambda x: model2.intercept_[0]+model2.coef_[0][0]*x])\n",
    "                                    T_ir[T_ir==model0.intercept_] = np.nan\n",
    "                                        \n",
    "                                if di==p0:\n",
    "                                    if utc<start_dates[5]:\n",
    "                                        T_ir[mask] = np.nan\n",
    "                                        pred_pa[mask] = np.nan\n",
    "                                # elif di==p00:\n",
    "                                #     if utc<=start_dates[3] and utc>=stop_dates[2]:\n",
    "                                #         T_ir[mask] = np.nan\n",
    "                                #         pred_pa_noon[mask] = np.nan      \n",
    "                                \n",
    "                                T_ir = T_ir*(1/.98)**(1/4)\n",
    "                            else:\n",
    "                                T_ir = np.nan*v.reshape(bgr.shape[0:2])\n",
    "    \n",
    "                            f_sol_sun.append(0)\n",
    "                            f_sol_shd.append(np.nansum(np.logical_or(pred_pa_noon==4,pred_pa_noon==0))/pred_pa_noon.shape[0]/pred_pa_noon.shape[1])\n",
    "                            f_res_sun.append(0)\n",
    "                            f_res_shd.append(np.nansum(np.logical_or(pred_pa_noon==5,pred_pa_noon==1))/pred_pa_noon.shape[0]/pred_pa_noon.shape[1])\n",
    "                            f_veg_sun.append(0)\n",
    "                            f_veg_shd.append(np.nansum(np.logical_or(pred_pa_noon==6,pred_pa_noon==2))/pred_pa_noon.shape[0]/pred_pa_noon.shape[1])\n",
    "                            f_snw_sun.append(0)\n",
    "                            f_snw_shd.append(np.nansum(np.logical_or(pred_pa_noon==7,pred_pa_noon==3))/pred_pa_noon.shape[0]/pred_pa_noon.shape[1])\n",
    "    \n",
    "                            T_sol_sun.append(np.nan)\n",
    "                            T_sol_shd.append(np.nanmean(T_ir[np.logical_or(pred_pa_noon==4,pred_pa_noon==0)]))\n",
    "                            T_res_sun.append(np.nan)\n",
    "                            T_res_shd.append(np.nanmean(T_ir[np.logical_or(pred_pa_noon==5,pred_pa_noon==1)]))\n",
    "                            T_veg_sun.append(np.nan)\n",
    "                            T_veg_shd.append(np.nanmean(T_ir[np.logical_or(pred_pa_noon==6,pred_pa_noon==2)]))\n",
    "                            T_snw_sun.append(np.nan)\n",
    "                            T_snw_shd.append(np.nanmean(T_ir[np.logical_or(pred_pa_noon==7,pred_pa_noon==3)]))\n",
    "                        \n",
    "                        else:\n",
    "                            f_sol_sun.append(np.nan)\n",
    "                            f_sol_shd.append(np.nan)\n",
    "                            f_res_sun.append(np.nan)\n",
    "                            f_res_shd.append(np.nan)\n",
    "                            f_veg_sun.append(np.nan)\n",
    "                            f_veg_shd.append(np.nan)\n",
    "                            f_snw_sun.append(np.nan)\n",
    "                            f_snw_shd.append(np.nan)\n",
    "    \n",
    "                            T_sol_sun.append(np.nan)\n",
    "                            T_sol_shd.append(np.nan)\n",
    "                            T_res_sun.append(np.nan)\n",
    "                            T_res_shd.append(np.nan)\n",
    "                            T_veg_sun.append(np.nan)\n",
    "                            T_veg_shd.append(np.nan)\n",
    "                            T_snw_sun.append(np.nan)\n",
    "                            T_snw_shd.append(np.nan)\n",
    "                except Exception as e:\n",
    "                    print(e,utc)\n",
    "                    print(traceback.format_exc())\n",
    "                    f_sol_sun.append(np.nan)\n",
    "                    f_sol_shd.append(np.nan)\n",
    "                    f_res_sun.append(np.nan)\n",
    "                    f_res_shd.append(np.nan)\n",
    "                    f_veg_sun.append(np.nan)\n",
    "                    f_veg_shd.append(np.nan)\n",
    "                    f_snw_sun.append(np.nan)\n",
    "                    f_snw_shd.append(np.nan)\n",
    "\n",
    "                    T_sol_sun.append(np.nan)\n",
    "                    T_sol_shd.append(np.nan)\n",
    "                    T_res_sun.append(np.nan)\n",
    "                    T_res_shd.append(np.nan)\n",
    "                    T_veg_sun.append(np.nan)\n",
    "                    T_veg_shd.append(np.nan)\n",
    "                    T_snw_sun.append(np.nan)\n",
    "                    T_snw_shd.append(np.nan)\n",
    "                    if theta>10.0:\n",
    "                        day = True\n",
    "                    else:\n",
    "                        day = False\n",
    "\n",
    "                daylight.append(day)\n",
    "                elevation.append(90-theta)\n",
    "                azimuth.append(phi)\n",
    "\n",
    "                times.append(utc)\n",
    "\n",
    "                n_img=n_img+1\n",
    "                ti_change = False\n",
    "            \n",
    "            elif utc>stop_dates[ti] and utc<stop_dates[-1]:\n",
    "                print(utc)\n",
    "                ti = ti+1\n",
    "                ti_change = True\n",
    "                warp_mat_assigned = False\n",
    "\n",
    "        print(len(times),len(daylight),len(elevation),len(f_sol_sun),len(T_sol_sun))\n",
    "        df = pd.DataFrame(data={'times':times,'daylight':daylight,'elevation':elevation,'azimuth':azimuth,'fssun':f_sol_sun,'fsshd':f_sol_shd,'frsun':f_res_sun,'frshd':f_res_shd,'fvsun':f_veg_sun,'fvshd':f_veg_shd,'fwsun':f_snw_sun,'fwshd':f_snw_shd,'Tssun':T_sol_sun,'Tsshd':T_sol_shd,'Trsun':T_res_sun,'Trshd':T_res_shd,'Tvsun':T_veg_sun,'Tvshd':T_veg_shd,'Twsun':T_snw_sun,'Twshd':T_snw_shd})\n",
    "        df.to_csv(os.path.join(p3,di.split('/')[-1].lower()+'_'+version+'_pa_output.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8763f2-f8dd-4f7a-943f-1d466b2fc869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsaru-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
