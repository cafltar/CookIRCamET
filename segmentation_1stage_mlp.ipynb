{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff53cd0-8993-45ef-829e-ed438a8c0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pysolar\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import dask.array as da\n",
    "from dask_ml.wrappers import Incremental\n",
    "from dask_ml.model_selection import SuccessiveHalvingSearchCV\n",
    "\n",
    "from pandas import read_csv, read_excel, DataFrame\n",
    "from skimage.feature import local_binary_pattern as LBP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "p0 = os.path.join('../../','raw','CookIRCamET','Images','CookHY2023')\n",
    "p1 = os.path.join('../../','work','CookIRCamET','Images','CookHY2023','V1','TifPng','RGB')\n",
    "p2 = os.path.join('../../','work','CookIRCamET','Images','CookHY2023','V1','TifPng')\n",
    "p00 = os.path.join('../../','raw','CookIRCamET','Images','CprlHY2023')\n",
    "p11 = os.path.join('../../','work','CookIRCamET','Images','CprlHY2023','V1','TifPng','RGB')\n",
    "p22 = os.path.join('../../','work','CookIRCamET','Images','CprlHY2023','V1','TifPng')\n",
    "p3 = os.path.join('../../','work','CookIRCamET','Working')\n",
    "\n",
    "n_components3 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168510ee-7314-421c-95fa-53dac75ff027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localSD(mat, n):    \n",
    "    mat=np.float32(mat)\n",
    "    mu = cv2.blur(mat,(n,n))\n",
    "    mdiff=mu-mat\n",
    "    mat2=cv2.blur(np.float64(mdiff*mdiff),(n,n))\n",
    "    sd = np.float32(cv2.sqrt(mat2))\n",
    "    \n",
    "    return sd\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffebfcf-e9ea-457f-804b-4f6701d61e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20221205160939_-117.081863_46.781553_bgr.png\n",
      "20221103153651_-117.081888_46.781508_bgr.png\n",
      "20230109215441_-117.081797_46.781650_bgr.png\n",
      "20221029174540_-117.081888_46.781508_bgr.png\n",
      "20221029201608_-117.081888_46.781508_bgr.png\n",
      "20221029191556_-117.081888_46.781508_bgr.png\n",
      "20221102233359_-117.081888_46.781508_bgr.png\n",
      "20221103000404_-117.081888_46.781508_bgr.png\n",
      "20221102153232_-117.081888_46.781508_bgr.png\n",
      "20221102160237_-117.081888_46.781508_bgr.png\n",
      "20221028234226_-117.081888_46.781508_bgr.png\n",
      "20230109222446_-117.081797_46.781650_bgr.png\n",
      "20221103150645_-117.081888_46.781508_bgr.png\n",
      "20221102223348_-117.081888_46.781508_bgr.png\n",
      "20221029211618_-117.081888_46.781508_bgr.png\n",
      "20221102203326_-117.081888_46.781508_bgr.png\n",
      "20221029154518_-117.081888_46.781508_bgr.png\n",
      "20221028231220_-117.081888_46.781508_bgr.png\n",
      "20221102220342_-117.081888_46.781508_bgr.png\n",
      "20230110152751_-117.081797_46.781650_bgr.png\n",
      "20221029184551_-117.081888_46.781508_bgr.png\n",
      "20221029204613_-117.081888_46.781508_bgr.png\n",
      "20221102213337_-117.081888_46.781508_bgr.png\n",
      "20221205153934_-117.081863_46.781553_bgr.png\n",
      "20221029194602_-117.081888_46.781508_bgr.png\n",
      "20221029144507_-117.081888_46.781508_bgr.png\n",
      "20221029161523_-117.081888_46.781508_bgr.png\n"
     ]
    }
   ],
   "source": [
    "f_imgs=[]\n",
    "imgs=[]\n",
    "n_img=0\n",
    "for di,do in zip([p1,p11],[p2,p22]):\n",
    "    fs=os.listdir(di)\n",
    "    shuffle(fs)\n",
    "    for f in fs:\n",
    "        if 'bgr' in f:\n",
    "\n",
    "            f_imgs = np.append(f_imgs,f)\n",
    "            bgr = cv2.imread(os.path.join(di,f),cv2.IMREAD_UNCHANGED)\n",
    "            time_place = f.split('_bgr.')[0].split('_')\n",
    "            if len(time_place)==3 or 'nofix' in f:#V1\n",
    "\n",
    "                labels = False\n",
    "                f_labels = os.path.join(do,'SunShade',f.split('_bgr')[0]+'_class2.tif')\n",
    "                if (os.path.exists(f_labels)):\n",
    "                    labels1 = cv2.imread(f_labels,cv2.IMREAD_UNCHANGED)\n",
    "                    labels = True\n",
    "\n",
    "                f_labels = os.path.join(do,'SoilResVegSnow',f.split('_bgr')[0]+'_class4.tif')\n",
    "                if (os.path.exists(f_labels)):\n",
    "                    labels2 = cv2.imread(f_labels,cv2.IMREAD_UNCHANGED)\n",
    "                    labels = (True & labels)\n",
    "                if labels: \n",
    "                     #8-class\n",
    "                    labels3 = 4*labels1+labels2\n",
    "                    if not os.path.exists(os.path.join(do,'Masks')): os.mkdir(os.path.join(do,'Masks'))\n",
    "                    cv2.imwrite(os.path.join(do,'Masks',f.split('_bgr')[0]+'_class8.tif'),labels3)\n",
    "                    print(f)\n",
    "                    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "                    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "                    img = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "                    l,a,bb = cv2.split(lab)\n",
    "                    h,s,v = cv2.split(hsv)\n",
    "\n",
    "                    sd_l1 = localSD(l, 127)\n",
    "                    sd_l2 = localSD(l, 63)\n",
    "                    sd_l3 = localSD(l, 31)\n",
    "\n",
    "                    lbp_l1 = LBP(l, 32, 4, method='ror')\n",
    "                    lbp_l2 = LBP(l, 24, 3, method='ror')\n",
    "                    lbp_l3 = LBP(l, 16, 2, method='ror')\n",
    "\n",
    "                    sd_a1 = localSD(a, 127)\n",
    "                    sd_a2 = localSD(a, 63)\n",
    "                    sd_a3 = localSD(a, 31)\n",
    "\n",
    "                    lbp_a1 = LBP(a, 32, 4, method='ror')\n",
    "                    lbp_a2 = LBP(a, 24, 3, method='ror')\n",
    "                    lbp_a3 = LBP(a, 16, 2, method='ror')\n",
    "\n",
    "                    sd_b1 = localSD(bb, 127)\n",
    "                    sd_b2 = localSD(bb, 63)\n",
    "                    sd_b3 = localSD(bb, 31)\n",
    "\n",
    "                    lbp_b1 = LBP(bb, 32, 4, method='ror')\n",
    "                    lbp_b2 = LBP(bb, 24, 3, method='ror')\n",
    "                    lbp_b3 = LBP(bb, 16, 2, method='ror')\n",
    "\n",
    "                    sd_h1 = localSD(h, 127)\n",
    "                    sd_h2 = localSD(h, 63)\n",
    "                    sd_h3 = localSD(h, 31)\n",
    "\n",
    "                    lbp_h1 = LBP(h, 32, 4, method='ror')\n",
    "                    lbp_h2 = LBP(h, 24, 3, method='ror')\n",
    "                    lbp_h3 = LBP(h, 16, 2, method='ror')\n",
    "\n",
    "                    sd_s1 = localSD(s, 127)\n",
    "                    sd_s2 = localSD(s, 63)\n",
    "                    sd_s3 = localSD(s, 31)\n",
    "\n",
    "                    lbp_s1 = LBP(s, 32, 4, method='ror')\n",
    "                    lbp_s2 = LBP(s, 24, 3, method='ror')\n",
    "                    lbp_s3 = LBP(s, 16, 2, method='ror')\n",
    "\n",
    "                    sd_v1 = localSD(v, 127)\n",
    "                    sd_v2 = localSD(v, 63)\n",
    "                    sd_v3 = localSD(v, 31)\n",
    "\n",
    "                    lbp_v1 = LBP(v, 32, 4, method='ror')\n",
    "                    lbp_v2 = LBP(v, 24, 3, method='ror')\n",
    "                    lbp_v3 = LBP(v, 16, 2, method='ror')\n",
    "\n",
    "                    ddepth = cv2.CV_16S\n",
    "\n",
    "                    lap_l1 = cv2.Laplacian(l,ddepth,ksize=3)\n",
    "                    lap_l2 = cv2.Laplacian(l,ddepth,ksize=7)\n",
    "                    lap_l3 = cv2.Laplacian(l,ddepth,ksize=15)\n",
    "\n",
    "                    lap_a1 = cv2.Laplacian(a,ddepth,ksize=3)\n",
    "                    lap_a2 = cv2.Laplacian(a,ddepth,ksize=7)\n",
    "                    lap_a3 = cv2.Laplacian(a,ddepth,ksize=15)\n",
    "\n",
    "                    lap_b1 = cv2.Laplacian(bb,ddepth,ksize=3)\n",
    "                    lap_b2 = cv2.Laplacian(bb,ddepth,ksize=7)\n",
    "                    lap_b3 = cv2.Laplacian(bb,ddepth,ksize=15)\n",
    "\n",
    "                    lap_h1 = cv2.Laplacian(h,ddepth,ksize=3)\n",
    "                    lap_h2 = cv2.Laplacian(h,ddepth,ksize=7)\n",
    "                    lap_h3 = cv2.Laplacian(h,ddepth,ksize=15)\n",
    "\n",
    "                    lap_s1 = cv2.Laplacian(s,ddepth,ksize=3)\n",
    "                    lap_s2 = cv2.Laplacian(s,ddepth,ksize=7)\n",
    "                    lap_s3 = cv2.Laplacian(s,ddepth,ksize=15)\n",
    "\n",
    "                    lap_v1 = cv2.Laplacian(v,ddepth,ksize=3)\n",
    "                    lap_v2 = cv2.Laplacian(v,ddepth,ksize=7)\n",
    "                    lap_v3 = cv2.Laplacian(v,ddepth,ksize=15)\n",
    "\n",
    "                    img_size = l.shape\n",
    "                    bb = bb.ravel()\n",
    "                    a = a.ravel()\n",
    "                    l = l.ravel()\n",
    "                    h = h.ravel()\n",
    "                    s = s.ravel()\n",
    "                    v = v.ravel()\n",
    "                    sd_l1 = sd_l1.ravel()\n",
    "                    sd_l2 = sd_l2.ravel()\n",
    "                    sd_l3 = sd_l3.ravel()\n",
    "                    lbp_l1 = lbp_l1.ravel()\n",
    "                    lbp_l2 = lbp_l2.ravel()\n",
    "                    lbp_l3 = lbp_l3.ravel()\n",
    "                    lap_l1 = lap_l1.ravel()\n",
    "                    lap_l2 = lap_l2.ravel()\n",
    "                    lap_l3 = lap_l3.ravel()\n",
    "                    sd_a1 = sd_a1.ravel()\n",
    "                    sd_a2 = sd_a2.ravel()\n",
    "                    sd_a3 = sd_a3.ravel()\n",
    "                    lbp_a1 = lbp_a1.ravel()\n",
    "                    lbp_a2 = lbp_a2.ravel()\n",
    "                    lbp_a3 = lbp_a3.ravel()\n",
    "                    lap_a1 = lap_a1.ravel()\n",
    "                    lap_a2 = lap_a2.ravel()\n",
    "                    lap_a3 = lap_a3.ravel()\n",
    "                    sd_b1 = sd_b1.ravel()\n",
    "                    sd_b2 = sd_b2.ravel()\n",
    "                    sd_b3 = sd_b3.ravel()\n",
    "                    lbp_b1 = lbp_b1.ravel()\n",
    "                    lbp_b2 = lbp_b2.ravel()\n",
    "                    lbp_b3 = lbp_b3.ravel()\n",
    "                    lap_b1 = lap_b1.ravel()\n",
    "                    lap_b2 = lap_b2.ravel()\n",
    "                    lap_b3 = lap_b3.ravel()\n",
    "                    sd_h1 = sd_h1.ravel()\n",
    "                    sd_h2 = sd_h2.ravel()\n",
    "                    sd_h3 = sd_h3.ravel()\n",
    "                    lbp_h1 = lbp_h1.ravel()\n",
    "                    lbp_h2 = lbp_h2.ravel()\n",
    "                    lbp_h3 = lbp_h3.ravel()\n",
    "                    lap_h1 = lap_h1.ravel()\n",
    "                    lap_h2 = lap_h2.ravel()\n",
    "                    lap_h3 = lap_h3.ravel()\n",
    "                    sd_s1 = sd_s1.ravel()\n",
    "                    sd_s2 = sd_s2.ravel()\n",
    "                    sd_s3 = sd_s3.ravel()\n",
    "                    lbp_s1 = lbp_s1.ravel()\n",
    "                    lbp_s2 = lbp_s2.ravel()\n",
    "                    lbp_s3 = lbp_s3.ravel()\n",
    "                    lap_s1 = lap_s1.ravel()\n",
    "                    lap_s2 = lap_s2.ravel()\n",
    "                    lap_s3 = lap_s3.ravel()\n",
    "                    sd_v1 = sd_v1.ravel()\n",
    "                    sd_v2 = sd_v2.ravel()\n",
    "                    sd_v3 = sd_v3.ravel()\n",
    "                    lbp_v1 = lbp_v1.ravel()\n",
    "                    lbp_v2 = lbp_v2.ravel()\n",
    "                    lbp_v3 = lbp_v3.ravel()\n",
    "                    lap_v1 = lap_v1.ravel()\n",
    "                    lap_v2 = lap_v2.ravel()\n",
    "                    lap_v3 = lap_v3.ravel()\n",
    "                    feat = np.vstack((l.T,a.T,bb.T,h.T,s.T,v.T,\n",
    "                                      sd_l1.T,sd_l2.T,sd_l3.T,\n",
    "                                      lbp_l1.T,lbp_l2.T,lbp_l3.T,\n",
    "                                      lap_l1.T,lap_l2.T,lap_l3.T,\n",
    "                                      sd_a1.T,sd_a2.T,sd_a3.T,\n",
    "                                      lbp_a1.T,lbp_a2.T,lbp_a3.T,\n",
    "                                      lap_a1.T,lap_a2.T,lap_a3.T,\n",
    "                                      sd_b1.T,sd_b2.T,sd_b3.T,\n",
    "                                      lbp_b1.T,lbp_b2.T,lbp_b3.T,\n",
    "                                      lap_b1.T,lap_b2.T,lap_b3.T,\n",
    "                                      sd_h1.T,sd_h2.T,sd_h3.T,\n",
    "                                      lbp_h1.T,lbp_h2.T,lbp_h3.T,\n",
    "                                      lap_h1.T,lap_h2.T,lap_h3.T,\n",
    "                                      sd_s1.T,sd_s2.T,sd_s3.T,\n",
    "                                      lbp_s1.T,lbp_s2.T,lbp_s3.T,\n",
    "                                      lap_s1.T,lap_s2.T,lap_s3.T,\n",
    "                                      sd_v1.T,sd_v2.T,sd_v3.T,\n",
    "                                      lbp_v1.T,lbp_v2.T,lbp_v3.T,\n",
    "                                      lap_v1.T,lap_v2.T,lap_v3.T)).T\n",
    "                    chunk = feat.shape\n",
    "                    #labels = np.sum(np.vstack((soil.ravel().T, residue.ravel().T*2, shadow.ravel().T*3, vegetation.ravel().T*4)).T,axis=1)\n",
    "                    labels1 = labels1.ravel()        \n",
    "                    labels2 = labels2.ravel() \n",
    "                    labels3 = labels3.ravel() \n",
    "\n",
    "                    if not np.any(np.isnan(feat)):\n",
    "                        imgs.append({'bgr':bgr,'feats':feat,'labels1':labels1,'labels2':labels2,'labels3':labels3})\n",
    "                        n_img=n_img+1\n",
    "\n",
    "                    del lab, hsv, img ,l , a, bb, h, s, v, sd_l1,sd_l2,sd_l3,lbp_l1,lbp_l2,lbp_l3,sd_a1,sd_a2,sd_a3,lbp_a1,lbp_a2,lbp_a3, sd_b1,sd_b2,sd_b3,lbp_b1,lbp_b2,lbp_b3, sd_h1,sd_h2,sd_h3,lbp_h1,lbp_h2,lbp_h3,sd_s1,sd_s2,sd_s3,lbp_s1,lbp_s2,lbp_s3, sd_v1,sd_v2,sd_v3,lbp_v1,lbp_v2,lbp_v3, lap_l1,lap_l2,lap_l3,lap_a1,lap_a2, lap_a3, lap_b1, lap_b2,lap_b3,lap_h1,lap_h2,lap_h3,lap_s1,lap_s2,lap_s3,lap_v1,lap_v2,lap_v3\n",
    "\n",
    "n_feat = feat.shape[1]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "feats = []\n",
    "labels3 = []\n",
    "for sample in imgs:\n",
    "    feats.append(sample['feats'])\n",
    "    labels3.append(sample['labels3'])\n",
    "\n",
    "del samples\n",
    "\n",
    "feats = [da.from_array(feat, chunks='auto') for feat in feats]\n",
    "feats = da.concatenate(feats).reshape((-1,n_feat)).astype(np.float32)\n",
    "labels3 = [da.from_array(label, chunks='auto') for label in labels3]\n",
    "labels3 = da.concatenate(labels3).reshape((-1,1)).astype(np.float32)\n",
    "classes = da.unique(labels3).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c727d0-aab6-45ad-8c7a-59acfce40135",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "filename = os.path.join(p3,'scaler_mlp.pk.sav')\n",
    "#with joblib.parallel_backend('dask', wait_for_workers_timeout=60):\n",
    "feats = scaler.fit_transform(feats)\n",
    "pickle.dump(scaler, open(filename, 'wb'))\n",
    "\n",
    "train_feats3, test_feats3, train_labels3, test_labels3 = train_test_split(feats, labels3, test_size=0.2, random_state=42)\n",
    "\n",
    "def cornfusion(obs,pred,nclass):\n",
    "    M = np.zeros((nclass,nclass))\n",
    "    for i in range(obs.shape[0]):\n",
    "        o = obs[i]\n",
    "        p = pred[i]\n",
    "        M[o,p] = M[o,p]+1\n",
    "    correct = sum(obs==pred)\n",
    "    total = len(pred)\n",
    "    M = M/np.sum(np.sum(M))\n",
    "    recall = np.diag(M)/np.sum(M,axis=1)\n",
    "    precis = np.diag(M)/np.sum(M,axis=0)\n",
    "\n",
    "    f1=(recall*precis/(recall+precis)*2)\n",
    "    f1_weighted=np.sum(f1*np.sum(M, axis=1))\n",
    "\n",
    "    return M, f1_weighted, correct/total\n",
    "\n",
    "train_feats = train_feats3#[:,mask3]\n",
    "test_feats = test_feats3#[:,mask3]\n",
    "clf_mlp3 = MLPClassifier(max_iter=100000,random_state=42,hidden_layer_sizes=[240,16],activation='logistic')\n",
    "inc = Incremental(clf_mlp3, scoring='accuracy')\n",
    "inc.fit(train_feats, train_labels3,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16dd3f05-0ceb-475d-a3f9-97230e117897",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7084/3097957046.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'scaler_mlp.pk.sav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#with joblib.parallel_backend('dask', wait_for_workers_timeout=60):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feats' is not defined"
     ]
    }
   ],
   "source": [
    "# layers = []\n",
    "\n",
    "# for layer1 in range(1,11):\n",
    "#     for layer2 in range(1,6):\n",
    "#         layer = (layer1*n_feat, int(np.sqrt(n_feat*n_components3*layer1*layer2)), layer2*n_components3)\n",
    "#         layers.append(layer)\n",
    "\n",
    "# parameters = {'activation':('relu','logistic'),'hidden_layer_sizes':layers}\n",
    "\n",
    "# mlp = MLPClassifier(max_iter=100000,random_state=42)\n",
    "# clf_mlp3 = HalvingGridSearchCV(mlp, parameters,n_jobs=-1,cv=5)\n",
    "\n",
    "# clf_mlp3.fit(train_feats, train_labels3)\n",
    "\n",
    "#model_mlp3 = clf_mlp3#.best_estimator_\n",
    "pred_mlp3 = inc.predict(test_feats)\n",
    "\n",
    "M_mlp3,f3,a3 = cornfusion(test_labels3,pred_mlp3,n_components3)\n",
    "\n",
    "plt.matshow(M_mlp3)\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.title(\"V1 Confusion Matrix\")\n",
    "plt.savefig(os.path.join(p3,'m_v1.png'),dpi=300)\n",
    "\n",
    "print(f3,a3)\n",
    "\n",
    "filename = os.path.join(p3,'finalized_model3_mlp_v1.pk.sav')\n",
    "pickle.dump(inc, open(filename, 'wb'))\n",
    "\n",
    "M_mlp3_df = {}\n",
    "M_mlp3_df['sun_soil'] = M_mlp3[:,0]\n",
    "M_mlp3_df['sun_res'] = M_mlp3[:,1]\n",
    "M_mlp3_df['sun_can'] = M_mlp3[:,2]\n",
    "M_mlp3_df['sun_snow'] = M_mlp3[:,3]\n",
    "M_mlp3_df['shade_soil'] = M_mlp3[:,4]\n",
    "M_mlp3_df['shade_res'] = M_mlp3[:,5]\n",
    "M_mlp3_df['shade_can'] = M_mlp3[:,6]\n",
    "M_mlp3_df['shade_snow'] = M_mlp3[:,7]\n",
    "M_mlp3_df = DataFrame(M_mlp3_df)\n",
    "M_mlp3_df.to_csv(os.path.join(p3,'M3_mlp_v1.csv'))\n",
    "\n",
    "# p3_df = DataFrame(clf_mlp3.best_params_)\n",
    "# p3_df.to_csv(os.path.join(p3,'params3_mlp_v2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e32047-7c3a-4484-8646-50e33872afab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
