{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5f0576-07d9-4009-92f3-a89745291288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pandas import read_csv, read_excel, DataFrame\n",
    "\n",
    "from skimage.feature import local_binary_pattern as LBP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from utils_segmentation import get_features, p3, p0, p00, n_components, plots, cornfusion\n",
    "\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc65b0-73a2-42b6-9be3-a5f3262ec09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2\n",
      "../../work/CookIRCamET/Images/CookHY2023/V2/TifPng/RGB\n",
      "../../work/CookIRCamET/Images/CookHY2023/V2/TifPng\n",
      "20230603_154524_bgr.png\n",
      "20230426_215539_bgr.png\n",
      "20230524_151215_bgr.png\n",
      "20230524_161216_bgr.png\n",
      "20230506_205714_bgr.png\n",
      "20230426_225539_bgr.png\n",
      "20230524_131214_bgr.png\n",
      "20230414_175343_bgr.png\n",
      "20230603_144524_bgr.png\n",
      "20230426_235540_bgr.png\n",
      "20230603_134524_bgr.png\n",
      "20230506_185713_bgr.png\n",
      "20230414_165342_bgr.png\n",
      "20230414_185343_bgr.png\n",
      "20230524_171216_bgr.png\n",
      "20230524_141215_bgr.png\n",
      "20230506_215714_bgr.png\n",
      "20230427_005540_bgr.png\n",
      "20230414_155342_bgr.png\n",
      "20230506_195713_bgr.png\n",
      "20230603_164525_bgr.png\n",
      "20230506_225715_bgr.png\n",
      "20230414_195344_bgr.png\n",
      "20230426_205538_bgr.png\n",
      "../../work/CookIRCamET/Images/CprlHY2023/V2/TifPng/RGB\n",
      "../../work/CookIRCamET/Images/CprlHY2023/V2/TifPng\n",
      "20230611153535_-102.095517_35.188213_bgr.png\n",
      "20230611113512_-102.095517_35.188213_bgr.png\n",
      "20230611163541_-102.095517_35.188213_bgr.png\n",
      "20230611133523_-102.095517_35.188213_bgr.png\n",
      "20230611123518_-102.095517_35.188213_bgr.png\n",
      "20230611143529_-102.095517_35.188213_bgr.png\n",
      "70\n",
      "[(140, 66, 32), (140, 94, 64), (280, 94, 32), (280, 133, 64)]\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 22118400\n",
      "max_resources_: 66355200\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 8\n",
      "n_resources: 22118400\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "model='mlp_batch'\n",
    "for version in ['V2','V1']:\n",
    "    print(version)\n",
    "    p1 = os.path.join('../../','work','CookIRCamET','Images','CookHY2023',version,'TifPng','RGB')\n",
    "    p2 = os.path.join('../../','work','CookIRCamET','Images','CookHY2023',version,'TifPng')\n",
    "    p11 = os.path.join('../../','work','CookIRCamET','Images','CprlHY2023',version,'TifPng','RGB')\n",
    "    p22 = os.path.join('../../','work','CookIRCamET','Images','CprlHY2023',version,'TifPng')\n",
    "    f_imgs=[]\n",
    "    imgs=[]\n",
    "    n_img=0\n",
    "    for di,do in zip([p1,p11],[p2,p22]):\n",
    "        fs=os.listdir(di)\n",
    "        print(di)\n",
    "        print(do)\n",
    "        shuffle(fs)\n",
    "        for f in fs:\n",
    "            if 'bgr' in f:\n",
    "    \n",
    "                f_imgs = np.append(f_imgs,f)\n",
    "                print(f)\n",
    "                filepath = os.path.join(di,f)\n",
    "                bgr = cv2.imread(filepath,cv2.IMREAD_UNCHANGED)\n",
    "                time_place = f.split('_bgr.')[0].split('_')\n",
    "    \n",
    "                labels = False\n",
    "                f_labels = os.path.join(do,'SunShade',f.split('_bgr')[0]+'_class2.tif')\n",
    "                if (os.path.exists(f_labels)):\n",
    "                    labels1 = cv2.imread(f_labels,cv2.IMREAD_UNCHANGED)\n",
    "                    labels = True\n",
    "    \n",
    "                f_labels = os.path.join(do,'SoilResVegSnow',f.split('_bgr')[0]+'_class4.tif')\n",
    "                if (os.path.exists(f_labels)):\n",
    "                    labels2 = cv2.imread(f_labels,cv2.IMREAD_UNCHANGED)\n",
    "                    labels2[labels2==4]=3#flowers->veg\n",
    "                    labels = (True & labels)\n",
    "                    if labels: \n",
    "                        #8-class\n",
    "                        labels3 = 4*labels1+labels2\n",
    "                        if not os.path.exists(os.path.join(do,'Masks')): os.mkdir(os.path.join(do,'Masks'))\n",
    "                        cv2.imwrite(os.path.join(do,'Masks',f.split('_bgr')[0]+'_class8.png'),labels3)\n",
    "    \n",
    "                    feat = get_features(bgr)\n",
    "                    labels1 = labels1.ravel()        \n",
    "                    labels2 = labels2.ravel() \n",
    "                    labels3 = labels3.ravel() \n",
    "    \n",
    "                    if not np.any(np.isnan(feat)):\n",
    "                        imgs.append({'bgr':bgr,'feats':feat,'labels1':labels1,'labels2':labels2,'labels3':labels3})\n",
    "                        n_img=n_img+1\n",
    "    \n",
    "    n_feat = feat.shape[1]\n",
    "    \n",
    "    feats_raw = []\n",
    "    labels3 = []\n",
    "    for sample in imgs:\n",
    "        feats_raw.append(sample['feats'])\n",
    "        labels3.append(sample['labels3'])\n",
    "    del imgs\n",
    "    \n",
    "    feats_raw = np.array(feats_raw).reshape((-1,n_feat)).astype(np.float32)\n",
    "    labels3 = np.array(labels3).reshape((-1,1)).astype(np.int32).ravel()\n",
    "    train_feats, test_feats, train_labels, test_labels = train_test_split(feats_raw, labels3, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Pipeline\n",
    "    #initial scaling\n",
    "    scaler = StandardScaler()\n",
    "    train_feats_scaled=scaler.fit_transform(train_feats)\n",
    "    #Best parameter (CV score=0.892): mlp v1\n",
    "    #{'clf__activation': 'logistic', 'clf__hidden_layer_sizes': (432, 117, 32), 'pca__n_components': 0.999}\n",
    "    #0.8922358777029111 0.8923369140625\n",
    "    #pca\n",
    "    pca = PCA(svd_solver='full',n_components=0.999)\n",
    "    train_feats_scaled_pca = pca.fit_transform(train_feats_scaled)\n",
    "    clf = MLPClassifier(max_iter=1000)\n",
    "    n_feat = train_feats_scaled_pca.shape[1]\n",
    "    #tune hyperparameters\n",
    "    print(n_feat)\n",
    "    layers = []\n",
    "\n",
    "    for layer1 in [2,4]:\n",
    "        for layer2 in [4,8]:\n",
    "            layer = (int(layer1*n_feat),int(np.sqrt(layer1*n_feat*layer2*n_components)),layer2*n_components)\n",
    "            layers.append(layer)\n",
    "    print(layers)\n",
    "    #parameters = {'pca__n_components':(0.99,0.999),'clf__hidden_layer_sizes':layers}\n",
    "    parameters = {'hidden_layer_sizes':layers,'activation':('relu','logistic')}\n",
    "\n",
    "    search = HalvingGridSearchCV(clf, parameters,n_jobs=-1,cv=5,verbose=3,aggressive_elimination=True)\n",
    "    \n",
    "    search.fit(train_feats_scaled_pca, train_labels)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    pipeline = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"clf\", search.best_estimator_)])\n",
    "    \n",
    "    filename = os.path.join(p3,'model_pipeline_'+version+'_'+model+'_final.pk.sav')\n",
    "    with open(filename, 'wb') as f:  # Python 3: open(..., 'wb'\n",
    "        pickle.dump(pipeline, f)\n",
    "        \n",
    "    pred = pipeline.predict(test_feats)\n",
    "\n",
    "    M,f,a = cornfusion(test_labels,pred,n_components)\n",
    "    \n",
    "    plt.matshow(M)\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.xlabel(\"Observed\")\n",
    "    plt.title(version+\" Confusion Matrix\")\n",
    "    plt.savefig(os.path.join(p3,'m_'+version+'_'+model+'_final.png'),dpi=300)\n",
    "    \n",
    "    print(f,a)\n",
    "    \n",
    "    M_df = {}\n",
    "    M_df['sun_soil'] = M[:,0]\n",
    "    M_df['sun_res'] = M[:,1]\n",
    "    M_df['sun_can'] = M[:,2]\n",
    "    M_df['sun_snow'] = M[:,3]\n",
    "    M_df['shade_soil'] = M[:,4]\n",
    "    M_df['shade_res'] = M[:,5]\n",
    "    M_df['shade_can'] = M[:,6]\n",
    "    M_df['shade_snow'] = M[:,7]\n",
    "    M_df = DataFrame(M_df)\n",
    "    M_df.to_csv(os.path.join(p3,'M_'+version+'_'+model+'_final.csv'))\n",
    "    \n",
    "    p_df = DataFrame(search.best_params_)\n",
    "    p_df.to_csv(os.path.join(p3,'params_'+version+'_'+model+'_final.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e767a3-5138-4012-a549-a8443c890ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsaru-cv",
   "language": "python",
   "name": "nsaru-cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
